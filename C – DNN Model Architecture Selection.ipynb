{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e6d56671-a83b-4883-87c7-8c5745831522",
   "metadata": {},
   "source": [
    "# C.\tModel Architecture Selection\n",
    "\n",
    "The optimal architecture for CNN and DNN models is determined, including veveral architectures are tested to identify the best-performing structure before full-scale training.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a249c4-2919-45ef-a7ba-243f2d8f4e62",
   "metadata": {},
   "source": [
    "## DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "124b63ab-290b-4a45-9bae-abeb702c17dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-06 03:37:13.685449: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-03-06 03:37:13.939113: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1741232234.049049    8921 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1741232234.074741    8921 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-03-06 03:37:14.351449: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from dnn_models import *\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from multiprocessing import Pool, Manager\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3afce108-1a02-4aa2-b51e-63c6e3228f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_features(df):\n",
    "    feature_groups = {}\n",
    "\n",
    "    for col in df.columns:\n",
    "        if col.startswith(\"DNN_\"):  # Filtra apenas colunas que começam com \"DNN_\"\n",
    "            parts = col.split(\"_\")\n",
    "            if len(parts) > 2:  # Garante que há pelo menos um conjunto intermediário\n",
    "                base_feature = \"_\".join(parts[1:-1])  # Pega todos os conjuntos entre o primeiro e o último\n",
    "                \n",
    "                if base_feature not in feature_groups:\n",
    "                    feature_groups[base_feature] = []\n",
    "                \n",
    "                feature_groups[base_feature].append(col)\n",
    "\n",
    "    return feature_groups\n",
    "\n",
    "def generate_filename(model_name, feature_group, batch_size, patience, epochs, learning_rate, extension):\n",
    "    \"\"\"\n",
    "    Generates a unique filename based on the given parameters.\n",
    "    \n",
    "    Args:\n",
    "        model_name (str): Name of the model.\n",
    "        feature_group (str): Name of the feature group.\n",
    "        batch_size (int): Batch size used for training.\n",
    "        patience (int): Patience value for early stopping.\n",
    "        epochs (int): Number of epochs.\n",
    "        learning_rate (float): Learning rate used for training.\n",
    "        extension (str): File extension (e.g., \".keras\" or \".csv\").\n",
    "        \n",
    "    Returns:\n",
    "        str: Generated filename.\n",
    "    \"\"\"\n",
    "    return f\"{model_name}_{feature_group}_bs{batch_size}_pat{patience}_ep{epochs}_lr{learning_rate}{extension}\"\n",
    "\n",
    "\n",
    "def train_and_evaluate(params, output_dir):\n",
    "    \"\"\"\n",
    "    Trains and evaluates a single combination of model, feature group, and hyperparameters.\n",
    "    Saves the trained model and metrics if they don't already exist.\n",
    "    \n",
    "    Args:\n",
    "        params (dict): A dictionary containing all necessary parameters for training and evaluation.\n",
    "        output_dir (str): Directory where models and metrics will be saved.\n",
    "        \n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    # Import TensorFlow and other dependencies inside the function\n",
    "    import tensorflow as tf\n",
    "    from tensorflow.keras.models import Sequential\n",
    "    from tensorflow.keras.layers import Dense, Dropout, BatchNormalization, LeakyReLU, Input\n",
    "    from tensorflow.keras.optimizers import Adam, RMSprop, SGD\n",
    "    from tensorflow.keras.callbacks import EarlyStopping\n",
    "    \n",
    "    # Unpack parameters\n",
    "    model_func = params[\"model_func\"]\n",
    "    X_train = params[\"X_train\"]\n",
    "    y_train = params[\"y_train\"]\n",
    "    X_val = params[\"X_val\"]\n",
    "    y_val = params[\"y_val\"]\n",
    "    X_test = params[\"X_test\"]\n",
    "    y_test = params[\"y_test\"]\n",
    "    input_dim = params[\"input_dim\"]\n",
    "    num_classes = params[\"num_classes\"]\n",
    "    epochs = params[\"epochs\"]\n",
    "    batch_size = params[\"batch_size\"]\n",
    "    patience = params[\"patience\"]\n",
    "    learning_rate = params[\"learning_rate\"]\n",
    "    monitor_metric = params[\"monitor_metric\"]\n",
    "    model_name = params[\"model_name\"]\n",
    "    feature_group = params[\"feature_group\"]\n",
    "    \n",
    "    # Generate filenames\n",
    "    model_filename = generate_filename(\n",
    "        model_name, feature_group, batch_size, patience, epochs, learning_rate, \".keras\"\n",
    "    )\n",
    "    metrics_filename = generate_filename(\n",
    "        model_name, feature_group, batch_size, patience, epochs, learning_rate, \".csv\"\n",
    "    )\n",
    "    \n",
    "    # Define paths\n",
    "    model_path = os.path.join(output_dir, \"models\", model_filename)\n",
    "    metrics_path = os.path.join(output_dir, \"metrics\", metrics_filename)\n",
    "    \n",
    "    # Check if model and metrics already exist\n",
    "    if os.path.exists(model_path) and os.path.exists(metrics_path):\n",
    "        #print(f\"Skipping training for {model_filename} (already exists)\")\n",
    "        return\n",
    "    \n",
    "    # Create and compile the model\n",
    "    model, optimizer = model_func(input_dim=input_dim, num_classes=num_classes, learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    # Define early stopping callback\n",
    "    early_stopping = EarlyStopping(\n",
    "        monitor=monitor_metric, patience=patience, restore_best_weights=True\n",
    "    )\n",
    "    \n",
    "    # Train the model\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_val, y_val),\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        callbacks=[early_stopping],\n",
    "        verbose=0\n",
    "    )\n",
    "    \n",
    "    # Evaluate the model on the test set\n",
    "    _, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "    \n",
    "    # Save the trained model\n",
    "    os.makedirs(os.path.dirname(model_path), exist_ok=True)\n",
    "    model.save(model_path)\n",
    "    print(f\"Saved model to {model_path}\")\n",
    "    \n",
    "    # Save the metrics\n",
    "    metrics = {\n",
    "        \"Model\": model_name,\n",
    "        \"Feature Group\": feature_group,\n",
    "        \"Batch Size\": batch_size,\n",
    "        \"Patience\": patience,\n",
    "        \"Epochs\": epochs,\n",
    "        \"Learning Rate\": learning_rate,\n",
    "        \"Monitor Metric\": monitor_metric,\n",
    "        \"Test Accuracy\": accuracy\n",
    "    }\n",
    "    os.makedirs(os.path.dirname(metrics_path), exist_ok=True)\n",
    "    metrics_df = pd.DataFrame([metrics])\n",
    "    metrics_df.to_csv(metrics_path, index=False)\n",
    "    print(f\"Saved metrics to {metrics_path}\")\n",
    "\n",
    "\n",
    "def test_dnn_models(output_dir, train_df, val_df, test_df, num_workers=10):\n",
    "    \"\"\"\n",
    "    Trains and evaluates multiple DNN models with different hyperparameter combinations,\n",
    "    saving the results to CSV files using parallel processing.\n",
    "    \n",
    "    Args:\n",
    "        output_dir (str): Directory where result CSV files will be saved.\n",
    "        train_df (pd.DataFrame): Training dataset.\n",
    "        val_df (pd.DataFrame): Validation dataset.\n",
    "        test_df (pd.DataFrame): Test dataset.\n",
    "        num_workers (int): Number of parallel workers.\n",
    "        \n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    # Define the hyperparameters to be tested\n",
    "    epochs_list = [50, 100]\n",
    "    batch_sizes = [64, 128]\n",
    "    patience_list = [3, 5, 10]\n",
    "    learning_rates = [0.001, 0.0005, 0.0001]\n",
    "    monitor_metric = 'val_accuracy'\n",
    "    \n",
    "    # Create the output directory if it doesn't exist\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    \n",
    "    # Group features based on their base feature names\n",
    "    feature_groups = group_features(train_df)\n",
    "    \n",
    "    # Define the DNN models to be tested\n",
    "    models = {\n",
    "        \"DNN-0\": create_model_0,\n",
    "        \"DNN-1\": create_model_1,\n",
    "        \"DNN-2\": create_model_2,\n",
    "        \"DNN-3\": create_model_3,\n",
    "        \"DNN-4\": create_model_4,\n",
    "        \"DNN-5\": create_model_5,\n",
    "        \"DNN-6\": create_model_3,\n",
    "        \"DNN-7\": create_model_4,\n",
    "        \"DNN-8\": create_model_5,\n",
    "        \"DNN-9\": create_model_5,\n",
    "    }\n",
    "    \n",
    "    # Determine the number of unique classes\n",
    "    num_classes = len(train_df['emotion'].unique())  # Determine the number of unique classes\n",
    "    \n",
    "    # Use raw integer targets instead of one-hot encoding\n",
    "    y_train = train_df['emotion'].values\n",
    "    y_val = val_df['emotion'].values\n",
    "    y_test = test_df['emotion'].values\n",
    "    \n",
    "    # Prepare all combinations of experiments\n",
    "    experiments = []\n",
    "    for model_name, model_func in models.items():\n",
    "        for feature_group, columns in feature_groups.items():\n",
    "            # Extract features for training, validation, and testing\n",
    "            X_train = train_df[columns].values\n",
    "            X_val = val_df[columns].values\n",
    "            X_test = test_df[columns].values\n",
    "            \n",
    "            # Get the number of input features dynamically\n",
    "            input_dim = X_train.shape[1]\n",
    "            \n",
    "            # Iterate over all hyperparameter combinations\n",
    "            for epochs in epochs_list:\n",
    "                for batch_size in batch_sizes:\n",
    "                    for patience in patience_list:\n",
    "                        for learning_rate in learning_rates:\n",
    "                            experiments.append({\n",
    "                                \"model_func\": model_func,\n",
    "                                \"X_train\": X_train,\n",
    "                                \"y_train\": y_train,\n",
    "                                \"X_val\": X_val,\n",
    "                                \"y_val\": y_val,\n",
    "                                \"X_test\": X_test,\n",
    "                                \"y_test\": y_test,\n",
    "                                \"input_dim\": input_dim,\n",
    "                                \"num_classes\": num_classes,\n",
    "                                \"epochs\": epochs,\n",
    "                                \"batch_size\": batch_size,\n",
    "                                \"patience\": patience,\n",
    "                                \"learning_rate\": learning_rate,\n",
    "                                \"monitor_metric\": monitor_metric,\n",
    "                                \"model_name\": model_name,\n",
    "                                \"feature_group\": feature_group\n",
    "                            })\n",
    "    \n",
    "    # Use multiprocessing to run experiments in parallel\n",
    "    with Pool(processes=num_workers) as pool:\n",
    "        # Map the experiments to the worker function\n",
    "        pool.starmap(train_and_evaluate, [(exp, output_dir) for exp in experiments])\n",
    "\n",
    "    print(\"All experiments completed. Models and metrics saved individually.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "474f1caf-8279-4d36-be26-576952d0957e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def process_model_metrics(output_dir):\n",
    "    \"\"\"\n",
    "    Processes all CSV files containing model evaluation metrics from <output_dir>/metrics,\n",
    "    aggregates them, and saves the consolidated results to two CSV files in <output_dir>.\n",
    "    \n",
    "    Args:\n",
    "        output_dir (str): Directory containing the 'metrics' folder with individual metric files.\n",
    "    \n",
    "    Returns:\n",
    "        None: The function saves the processed results to two CSV files in the specified directory.\n",
    "    \"\"\"\n",
    "    # Define paths\n",
    "    metrics_dir = os.path.join(output_dir, \"metrics\")\n",
    "    consolidated_no_features_path = os.path.join(output_dir, \"consolidated_no_features.csv\")\n",
    "    consolidated_total_path = os.path.join(output_dir, \"consolidated_total.csv\")\n",
    "    \n",
    "    # Check if the metrics directory exists\n",
    "    if not os.path.exists(metrics_dir):\n",
    "        raise FileNotFoundError(f\"The directory '{metrics_dir}' does not exist.\")\n",
    "    \n",
    "    # Get all CSV files in the metrics directory\n",
    "    file_paths = [os.path.join(metrics_dir, f) for f in os.listdir(metrics_dir) if f.endswith(\".csv\")]\n",
    "    if not file_paths:\n",
    "        raise ValueError(f\"No CSV files found in '{metrics_dir}'.\")\n",
    "    \n",
    "    # Initialize DataFrame for consolidation\n",
    "    df_total = pd.DataFrame()\n",
    "    \n",
    "    # Process each CSV file\n",
    "    for file_path in file_paths:\n",
    "        df = pd.read_csv(file_path)\n",
    "        df_total = pd.concat([df_total, df], ignore_index=True)  # Append all data to a single DataFrame\n",
    "    \n",
    "    # Save raw consolidated data\n",
    "    df_total = df_total.sort_values(by='Test Accuracy', ascending=False)\n",
    "    df_total.to_csv(consolidated_total_path, index=False)\n",
    "    print(f\"Saved consolidated total results to {consolidated_total_path}\")\n",
    "    \n",
    "    # Remove 'Feature Group' column if it exists\n",
    "    df_no_features = df_total.drop(columns=['Feature Group'], errors='ignore')\n",
    "    \n",
    "    # Aggregate data by averaging Test Accuracy across all feature groups for each model-hyperparameter combination\n",
    "    df_grouped_total = df_no_features.groupby([\n",
    "        'Model', 'Batch Size', 'Patience', 'Epochs', 'Learning Rate', 'Monitor Metric'\n",
    "    ], as_index=False).mean()\n",
    "\n",
    "    # Sort the grouped results by Test Accuracy in descending order\n",
    "    df_grouped_total = df_grouped_total.sort_values(by='Test Accuracy', ascending=False)\n",
    "\n",
    "    # Save aggregated results\n",
    "    df_grouped_total.to_csv(consolidated_no_features_path, index=False)\n",
    "    print(f\"Saved consolidated results without Feature Group to {consolidated_no_features_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6526e92b-9df2-4bb4-982d-88a02abb9d96",
   "metadata": {},
   "source": [
    "## Train one model per feature. Collect metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cc853148-4a6c-4403-a986-0d5a65154395",
   "metadata": {},
   "outputs": [],
   "source": [
    "DNN_train = joblib.load(\"DNN_train.joblib\")\n",
    "DNN_val = joblib.load(\"DNN_val.joblib\")\n",
    "DNN_val2 = joblib.load(\"DNN_val2.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ab48b5a-e674-4e18-ac76-5add76540acd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "DNN_SELECTION_DIR = \"DNN_SELECTION\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5092fb3e-a410-4501-a016-b2c30f7077a3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All experiments completed. Models and metrics saved individually.\n"
     ]
    }
   ],
   "source": [
    "test_dnn_models(DNN_SELECTION_DIR, DNN_train, DNN_val, DNN_val2, num_workers=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "227cccd3-aba1-4131-b14b-3b9a03743f7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved consolidated total results to DNN_SELECTION/consolidated_total.csv\n",
      "Saved consolidated results without Feature Group to DNN_SELECTION/consolidated_no_features.csv\n"
     ]
    }
   ],
   "source": [
    "process_model_metrics(DNN_SELECTION_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f9058b-82e2-4dc5-9e59-29bf1d92bc1b",
   "metadata": {},
   "source": [
    "## Select the best model with the best mean accuracy among all features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4c621b93-6ec6-484f-b170-dfefc9b4074c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Batch Size</th>\n",
       "      <th>Patience</th>\n",
       "      <th>Epochs</th>\n",
       "      <th>Learning Rate</th>\n",
       "      <th>Monitor Metric</th>\n",
       "      <th>Test Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DNN-6</td>\n",
       "      <td>64</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>val_accuracy</td>\n",
       "      <td>0.30353</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Model  Batch Size  Patience  Epochs  Learning Rate Monitor Metric  \\\n",
       "0  DNN-6          64        10     100         0.0005   val_accuracy   \n",
       "\n",
       "   Test Accuracy  \n",
       "0        0.30353  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_metrics = pd.read_csv(os.path.join(DNN_SELECTION_DIR, \"consolidated_no_features.csv\"))\n",
    "results_metrics.head(1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e9c0c4-0bae-4d07-a5a1-1e511e324ae4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f803409f-28e2-4b30-a0ba-51fb15c52f48",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
